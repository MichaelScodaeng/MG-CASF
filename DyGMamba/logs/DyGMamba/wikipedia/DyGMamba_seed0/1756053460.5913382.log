2025-08-25 01:37:40,593 - root - INFO - ********** Run 1 starts. **********
2025-08-25 01:37:40,593 - root - INFO - configuration is Namespace(dataset_name='wikipedia', batch_size=200, model_name='DyGMamba', gpu=0, num_neighbors=20, sample_neighbor_strategy='uniform', time_scaling_factor=1e-06, num_walk_heads=8, num_heads=2, num_layers=2, walk_length=1, time_gap=2000, time_feat_dim=100, position_feat_dim=172, time_window_mode='fixed_proportion', patch_size=1, channel_embedding_dim=50, max_input_sequence_length=32, learning_rate=0.0001, dropout=0.1, gamma=0.5, num_epochs=100, optimizer='Adam', weight_decay=0.0, patience=20, val_ratio=0.15, test_ratio=0.15, num_runs=1, test_interval_epochs=1, negative_sample_strategy='random', max_interaction_times=10, load_best_configs=False, fusion_strategy='use', spatial_dim=64, temporal_dim=64, ccasf_output_dim=128, use_integrated_mpgnn=True, use_sequential_fallback=False, embedding_mode='spatiotemporal_only', enable_base_embedding=False, rpearl_hidden=64, rpearl_mlp_layers=2, rpearl_k=16, lete_hidden=64, lete_layers=2, lete_p=0.5, use_hidden_dim=128, use_num_casm_layers=3, use_num_smpn_layers=3, caga_hidden_dim=128, caga_num_heads=8, clifford_dim=4, clifford_signature='euclidean', use_memory=False, memory_dim=128, output_dim=128, mamba_d_model=128, mamba_d_state=16, mamba_d_conv=4, mamba_expand=2, enable_feature_caching=True, clear_cache_interval=100, n_degree=20, n_head=2, n_layer=2, drop_out=0.1, lr=0.0001, n_epoch=100, seed=0, uniform=False, different_new_nodes=False, device='cuda:0', save_model_name='DyGMamba_seed0')
2025-08-25 01:37:40,593 - root - INFO - ðŸ§  Using INTEGRATED MPGNN approach (theoretical compliance)
2025-08-25 01:37:40,639 - root - INFO - âœ… Integrated DyGMamba created successfully
2025-08-25 01:37:40,639 - root - INFO -    Embedding mode: spatiotemporal_only
2025-08-25 01:37:40,639 - root - INFO -    Base embedding: Disabled
2025-08-25 01:37:40,639 - root - INFO -    Fusion strategy: use
2025-08-25 01:37:40,639 - root - INFO -    Theoretical compliance: MPGNN âœ“
2025-08-25 01:37:40,639 - root - INFO - Using enhanced feature dimension for link predictor: 300
2025-08-25 01:37:40,641 - root - INFO - Model approach: ðŸ§  INTEGRATED MPGNN (theoretical)
2025-08-25 01:37:40,642 - root - INFO - model -> Sequential(
  (0): IntegratedDyGMamba(
    (enhanced_feature_manager): EnhancedNodeFeatureManager(
      (spatial_generator): TrainableSpatialGenerator(
        (spatial_encoder): Sequential(
          (spatial_layer_0): Sequential(
            (0): Linear(in_features=172, out_features=64, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (spatial_layer_1): Sequential(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (spatial_output): Linear(in_features=64, out_features=64, bias=True)
        (position_encoder): Embedding(16, 64)
        (time_spatial_encoder): Linear(in_features=1, out_features=64, bias=True)
      )
      (temporal_generator): TrainableTemporalGenerator(
        (time_encoder): TimeEncoder(
          (w): Linear(in_features=1, out_features=100, bias=True)
        )
        (temporal_encoder): Sequential(
          (temporal_layer_0): Sequential(
            (0): Linear(in_features=272, out_features=64, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (temporal_layer_1): Sequential(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (temporal_output): Linear(in_features=64, out_features=64, bias=True)
      )
      (fusion_module): TrainableUSEFusion(
        (casm_net): Sequential(
          (casm_layer_0): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (casm_layer_1): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (casm_layer_2): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
        (casm_output): Linear(in_features=128, out_features=16, bias=True)
        (smpn): Sequential(
          (smpn_layer_0): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (smpn_layer_1): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (smpn_layer_2): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
        )
        (smpn_output): Linear(in_features=128, out_features=16, bias=True)
        (final_projection): Linear(in_features=16, out_features=128, bias=True)
      )
    )
  )
  (1): MergeLayerTD(
    (fc1): Linear(in_features=900, out_features=300, bias=True)
    (fc2): Linear(in_features=300, out_features=1, bias=True)
    (act): ReLU()
  )
)
2025-08-25 01:37:40,643 - root - INFO - model name: DyGMamba, #parameters: 1699524 B, 1659.69140625 KB, 1.6207923889160156 MB.
2025-08-25 01:40:30,779 - root - INFO - Epoch: 1, learning rate: 0.0001, train loss: 0.6951
2025-08-25 01:40:30,780 - root - INFO - train average_precision, 0.5929
2025-08-25 01:40:30,780 - root - INFO - train roc_auc, 0.4920
2025-08-25 01:40:30,780 - root - INFO - validate loss: 0.6957
2025-08-25 01:40:30,780 - root - INFO - validate average_precision, 0.5910
2025-08-25 01:40:30,780 - root - INFO - validate roc_auc, 0.4955
2025-08-25 01:40:30,780 - root - INFO - new node validate loss: 0.6957
2025-08-25 01:40:30,780 - root - INFO - new node validate average_precision, 0.5750
2025-08-25 01:40:30,780 - root - INFO - new node validate roc_auc, 0.4706
2025-08-25 01:41:14,829 - root - INFO - test loss: 0.6917
2025-08-25 01:41:14,829 - root - INFO - test average_precision, 0.6209
2025-08-25 01:41:14,829 - root - INFO - best test average_precision: 0.6209
2025-08-25 01:41:14,830 - root - INFO - test roc_auc, 0.5257
2025-08-25 01:41:14,830 - root - INFO - new node test loss: 0.7035
2025-08-25 01:41:14,830 - root - INFO - new node test average_precision, 0.5613
2025-08-25 01:41:14,830 - root - INFO - new node test roc_auc, 0.4402
2025-08-25 01:41:14,878 - root - INFO - save model ./saved_models/DyGMamba/wikipedia/DyGMamba_seed0/DyGMamba_seed0.pkl
2025-08-25 01:43:55,638 - root - INFO - Epoch: 2, learning rate: 0.0001, train loss: 0.6992
2025-08-25 01:43:55,638 - root - INFO - train average_precision, 0.5985
2025-08-25 01:43:55,638 - root - INFO - train roc_auc, 0.4844
2025-08-25 01:43:55,638 - root - INFO - validate loss: 0.7013
2025-08-25 01:43:55,638 - root - INFO - validate average_precision, 0.5883
2025-08-25 01:43:55,638 - root - INFO - validate roc_auc, 0.4790
2025-08-25 01:43:55,639 - root - INFO - new node validate loss: 0.7041
2025-08-25 01:43:55,639 - root - INFO - new node validate average_precision, 0.5652
2025-08-25 01:43:55,639 - root - INFO - new node validate roc_auc, 0.4491
2025-08-25 01:44:38,464 - root - INFO - test loss: 0.6987
2025-08-25 01:44:38,465 - root - INFO - test average_precision, 0.6026
2025-08-25 01:44:38,465 - root - INFO - best test average_precision: 0.6209
2025-08-25 01:44:38,465 - root - INFO - test roc_auc, 0.4937
2025-08-25 01:44:38,465 - root - INFO - new node test loss: 0.6980
2025-08-25 01:44:38,465 - root - INFO - new node test average_precision, 0.6009
2025-08-25 01:44:38,465 - root - INFO - new node test roc_auc, 0.5054
