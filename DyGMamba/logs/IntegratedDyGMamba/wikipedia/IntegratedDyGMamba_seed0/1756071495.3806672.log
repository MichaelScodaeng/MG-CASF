2025-08-25 06:38:15,382 - root - INFO - ********** Run 1 starts. **********
2025-08-25 06:38:15,383 - root - INFO - configuration is Namespace(dataset_name='wikipedia', batch_size=200, model_name='IntegratedDyGMamba', gpu=0, num_neighbors=20, sample_neighbor_strategy='uniform', time_scaling_factor=1e-06, num_walk_heads=8, num_heads=2, num_layers=2, walk_length=1, time_gap=2000, time_feat_dim=100, position_feat_dim=172, time_window_mode='fixed_proportion', patch_size=1, channel_embedding_dim=50, max_input_sequence_length=32, learning_rate=0.0001, dropout=0.1, gamma=0.5, num_epochs=100, optimizer='Adam', weight_decay=0.0, patience=20, val_ratio=0.15, test_ratio=0.15, num_runs=1, test_interval_epochs=1, negative_sample_strategy='random', max_interaction_times=10, load_best_configs=False, fusion_strategy='clifford', spatial_dim=64, temporal_dim=64, ccasf_output_dim=128, use_integrated_mpgnn=True, use_sequential_fallback=False, embedding_mode='spatiotemporal_only', enable_base_embedding=False, rpearl_hidden=64, rpearl_mlp_layers=2, rpearl_k=16, lete_hidden=64, lete_layers=2, lete_p=0.5, use_hidden_dim=128, use_num_casm_layers=3, use_num_smpn_layers=3, caga_hidden_dim=128, caga_num_heads=8, clifford_dim=4, clifford_signature='euclidean', use_memory=False, memory_dim=128, output_dim=128, mamba_d_model=128, mamba_d_state=16, mamba_d_conv=4, mamba_expand=2, enable_feature_caching=True, clear_cache_interval=100, n_degree=20, n_head=2, n_layer=2, drop_out=0.1, lr=0.0001, n_epoch=100, seed=0, uniform=False, different_new_nodes=False, device='cuda:0', save_model_name='IntegratedDyGMamba_seed0')
2025-08-25 06:38:15,383 - root - INFO - ðŸ§  Using INTEGRATED MPGNN approach (theoretical compliance)
2025-08-25 06:38:16,769 - root - INFO - âœ… Integrated IntegratedDyGMamba created successfully
2025-08-25 06:38:16,769 - root - INFO -    Embedding mode: spatiotemporal_only
2025-08-25 06:38:16,769 - root - INFO -    Base embedding: Disabled
2025-08-25 06:38:16,769 - root - INFO -    Fusion strategy: clifford
2025-08-25 06:38:16,769 - root - INFO -    Theoretical compliance: MPGNN âœ“
2025-08-25 06:38:16,769 - root - INFO - Using enhanced feature dimension for link predictor: 300
2025-08-25 06:38:16,771 - root - INFO - Model approach: ðŸ§  INTEGRATED MPGNN (theoretical)
2025-08-25 06:38:16,772 - root - INFO - model -> Sequential(
  (0): IntegratedDyGMamba(
    (enhanced_feature_manager): EnhancedNodeFeatureManager(
      (spatial_generator): TrainableSpatialGenerator(
        (spatial_encoder): Sequential(
          (spatial_layer_0): Sequential(
            (0): Linear(in_features=172, out_features=64, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (spatial_layer_1): Sequential(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): ReLU()
            (2): Dropout(p=0.1, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (spatial_output): Linear(in_features=64, out_features=64, bias=True)
        (position_encoder): Embedding(16, 64)
        (time_spatial_encoder): Linear(in_features=1, out_features=64, bias=True)
      )
      (temporal_generator): TrainableTemporalGenerator(
        (time_encoder): TimeEncoder(
          (w): Linear(in_features=1, out_features=100, bias=True)
        )
        (temporal_encoder): Sequential(
          (temporal_layer_0): Sequential(
            (0): Linear(in_features=272, out_features=64, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (temporal_layer_1): Sequential(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
        (temporal_output): Linear(in_features=64, out_features=64, bias=True)
      )
      (fusion_module): TrainableCliffordFusion(
        (clifford_mv): CliffordMultivector()
        (spatial_to_clifford): Linear(in_features=64, out_features=16, bias=True)
        (temporal_to_clifford): Linear(in_features=64, out_features=16, bias=True)
        (final_projection): Linear(in_features=16, out_features=128, bias=True)
      )
    )
    (dygmamba_backbone): DyGMamba(
      (time_encoder): TimeEncoder(
        (w): Linear(in_features=1, out_features=100, bias=True)
      )
      (neighbor_co_occurrence_encoder): NIFEncoder(
        (nif_encode_layer): Sequential(
          (0): Linear(in_features=1, out_features=50, bias=True)
          (1): ReLU()
          (2): Linear(in_features=50, out_features=50, bias=True)
        )
      )
      (projection_layer): ModuleDict(
        (node): Linear(in_features=172, out_features=50, bias=True)
        (edge): Linear(in_features=172, out_features=50, bias=True)
        (time): Linear(in_features=100, out_features=50, bias=True)
        (neighbor_co_occurrence): Linear(in_features=50, out_features=50, bias=True)
      )
      (output_layer): Linear(in_features=100, out_features=172, bias=True)
      (output_layer_t_diff): Linear(in_features=25, out_features=172, bias=True)
      (mamba): ModuleList(
        (0-1): 2 x Mamba(
          (in_proj): Linear(in_features=100, out_features=200, bias=False)
          (conv1d): Conv1d(100, 100, kernel_size=(4,), stride=(1,), padding=(3,), groups=100)
          (act): SiLU()
          (x_proj): Linear(in_features=100, out_features=39, bias=False)
          (dt_proj): Linear(in_features=7, out_features=100, bias=True)
          (out_proj): Linear(in_features=100, out_features=100, bias=False)
        )
      )
      (mamba_t_diff): ModuleList(
        (0-1): 2 x Mamba(
          (in_proj): Linear(in_features=25, out_features=50, bias=False)
          (conv1d): Conv1d(25, 25, kernel_size=(4,), stride=(1,), padding=(3,), groups=25)
          (act): SiLU()
          (x_proj): Linear(in_features=25, out_features=34, bias=False)
          (dt_proj): Linear(in_features=2, out_features=25, bias=True)
          (out_proj): Linear(in_features=25, out_features=25, bias=False)
        )
      )
      (projection_layer_t_diff): Linear(in_features=100, out_features=25, bias=True)
      (projection_layer_t_diff_up): Linear(in_features=25, out_features=100, bias=True)
      (weightagg): Linear(in_features=100, out_features=1, bias=True)
      (reduce_layer): Linear(in_features=200, out_features=100, bias=True)
      (channel_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
      (channel_feedforward): FeedForwardNet(
        (ffn): Sequential(
          (0): Linear(in_features=100, out_features=400, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=400, out_features=100, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (neighbor_selection_layer): Linear(in_features=100, out_features=100, bias=True)
    )
  )
  (1): MergeLayerTD(
    (fc1): Linear(in_features=900, out_features=300, bias=True)
    (fc2): Linear(in_features=300, out_features=1, bias=True)
    (act): ReLU()
  )
)
2025-08-25 06:38:16,773 - root - INFO - model name: IntegratedDyGMamba, #parameters: 2273780 B, 2220.48828125 KB, 2.168445587158203 MB.
