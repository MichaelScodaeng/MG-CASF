2025-08-16 17:33:11,684 - INFO - Starting experiment: ccasf_cross_attention on wikipedia
2025-08-16 17:33:11,684 - INFO - Device: cuda
2025-08-16 17:33:11,684 - INFO - 
==================================================
2025-08-16 17:33:11,684 - INFO - Run 1/1 - TGN with cross_attention
2025-08-16 17:33:11,684 - INFO - ==================================================
2025-08-16 17:33:11,687 - INFO - Starting training for wikipedia with C-CASF
2025-08-16 17:33:11,687 - INFO - Configuration: {'dataset_name': 'wikipedia', 'model_name': 'TGN', 'use_ccasf': True, 'spatial_dim': 64, 'temporal_dim': 64, 'ccasf_output_dim': 128, 'node_feat_dim': 172, 'edge_feat_dim': 172, 'fusion_method': 'cross_attention', 'weighted_fusion_learnable': True, 'mlp_hidden_dim': None, 'mlp_num_layers': 2, 'cross_attn_heads': 8, 'use_rpearl': True, 'use_enhanced_lete': True, 'rpearl_k': 16, 'rpearl_mlp_layers': 2, 'rpearl_hidden': 64, 'lete_p': 0.5, 'lete_layer_norm': True, 'lete_scale': True, 'time_feat_dim': 100, 'channel_embedding_dim': 100, 'patch_size': 2, 'num_layers': 2, 'num_heads': 2, 'dropout': 0.1, 'gamma': 0.5, 'max_input_sequence_length': 64, 'max_interaction_times': 10, 'learning_rate': 0.0001, 'weight_decay': 0.01, 'patience': 20, 'num_epochs': 3, 'batch_size': 200, 'eval_batch_size': 200, 'test_batch_size': 200, 'val_ratio': 0.15, 'test_ratio': 0.15, 'negative_sample_strategy': 'random', 'num_neighbors': 20, 'num_runs': 1, 'load_best_configs': False, 'device': 'cuda', 'num_workers': 8, 'seed': 0, 'data_root': '/home/s2516027/GLCE/processed_data', 'output_root': '/home/s2516027/GLCE/results', 'checkpoint_dir': '/home/s2516027/GLCE/checkpoints', 'log_every': 1, 'eval_every': 5, 'save_model': True, 'verbose': True}
2025-08-16 17:33:11,688 - INFO - Loading wikipedia dataset...
2025-08-16 17:33:12,100 - INFO - Number of nodes: 9228
2025-08-16 17:33:12,100 - INFO - Number of edges: 157475
2025-08-16 17:33:12,100 - INFO - Node feature dimension: 172
2025-08-16 17:33:12,100 - INFO - Edge feature dimension: 172
2025-08-16 17:33:12,100 - INFO - Training interactions: 79202
2025-08-16 17:33:12,100 - INFO - Validation interactions: 23621
2025-08-16 17:33:12,101 - INFO - Test interactions: 23621
2025-08-16 17:33:12,611 - INFO - Creating model: TGN
2025-08-16 17:33:12,860 - INFO - Wrapping TGN with C-CASF
2025-08-16 17:33:12,861 - INFO - Model created with 1460585 parameters
2025-08-16 17:33:12,870 - INFO - Sorted training data by timestamp for memory-based model TGN
2025-08-16 17:33:14,509 - ERROR - Error in batch 2
Traceback (most recent call last):
  File "/home/s2516027/GLCE/DyGMamba/train_ccasf_link_prediction.py", line 534, in train_epoch
    loss.backward()
  File "/home/s2516027/anaconda3/envs/glce/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/s2516027/anaconda3/envs/glce/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/s2516027/anaconda3/envs/glce/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [516]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-08-16 17:33:14,511 - ERROR - Error in run 0
Traceback (most recent call last):
  File "/home/s2516027/GLCE/DyGMamba/train_ccasf_link_prediction.py", line 894, in main
    results, model = train_model(config, logger)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s2516027/GLCE/DyGMamba/train_ccasf_link_prediction.py", line 678, in train_model
    train_loss = train_epoch(model, train_data, train_idx_loader, train_neg_sampler, optimizer, criterion, config, logger)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s2516027/GLCE/DyGMamba/train_ccasf_link_prediction.py", line 534, in train_epoch
    loss.backward()
  File "/home/s2516027/anaconda3/envs/glce/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/s2516027/anaconda3/envs/glce/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/s2516027/anaconda3/envs/glce/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [516]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
